
package com.hedera.parser;

/*-
 * ‌
 * Hedera Mirror Node
 * ​
 * Copyright (C) 2019 Hedera Hashgraph, LLC
 * ​
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *      http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * ‍
 */

import java.io.DataInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.nio.file.Paths;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.stream.Collectors;

import com.google.common.base.Stopwatch;
import com.google.protobuf.TextFormat;
import com.hedera.configLoader.ConfigLoader;
import com.hedera.configLoader.ConfigLoader.OPERATION_TYPE;
import com.hedera.mirror.domain.ApplicationStatusCode;
import com.hedera.mirror.repository.ApplicationStatusRepository;
import com.hedera.filedelimiters.FileDelimiter;
import com.hedera.mirror.config.RecordProperties;
import com.hedera.recordFileLogger.RecordFileLogger;
import com.hedera.recordFileLogger.RecordFileLogger.INIT_RESULT;
import com.hedera.utilities.Utility;
import com.hederahashgraph.api.proto.java.Transaction;
import com.hederahashgraph.api.proto.java.TransactionRecord;
import lombok.extern.log4j.Log4j2;
import org.apache.commons.codec.binary.Hex;
import org.apache.commons.lang3.StringUtils;
import org.springframework.scheduling.annotation.Scheduled;

import javax.inject.Named;

/**
 * This is a utility file to read back service record file generated by Hedera node
 */
@Log4j2
@Named
public class RecordFileParser implements FileParser {

	private final ApplicationStatusRepository applicationStatusRepository;
	private final RecordProperties recordProperties;

	public RecordFileParser(ApplicationStatusRepository applicationStatusRepository, RecordProperties recordProperties) {
		this.applicationStatusRepository = applicationStatusRepository;
		this.recordProperties = recordProperties;
		Utility.ensureDirectory(ConfigLoader.getDefaultParseDir(OPERATION_TYPE.RECORDS));
		Utility.ensureDirectory(Paths.get(ConfigLoader.getDownloadToDir(), "parsedRecordFiles").toString());
	}

	/**
	 * Given a service record name, read and parse and return as a list of service record pair
	 *
	 * @param fileName
	 * 		the name of record file to read
	 * @param previousFileHash
	 * 		the hash of the previous record file in the series
	 * @param thisFileHash
	 * 		the hash of this file
	 * @return return boolean indicating method success
	 * @throws Exception 
	 */
	private boolean loadRecordFile(String fileName, String previousFileHash, String thisFileHash) throws Exception {

		File file = new File(fileName);
		String newFileHash = "";
		
		if (file.exists() == false) {
			log.warn("File does not exist {}", fileName);
			return false;
		}
		long counter = 0;
		byte[] readFileHash = new byte[48];
		INIT_RESULT initFileResult = RecordFileLogger.initFile(fileName);
		Stopwatch stopwatch = Stopwatch.createStarted();

		if (initFileResult == INIT_RESULT.OK) {
			try (DataInputStream dis = new DataInputStream(new FileInputStream(file))) {
				int record_format_version = dis.readInt();
				int version = dis.readInt();

				log.info("Loading version {} record file: {}", record_format_version, file.getName());

				while (dis.available() != 0) {

					try {
						byte typeDelimiter = dis.readByte();

						switch (typeDelimiter) {
							case FileDelimiter.RECORD_TYPE_PREV_HASH:
								dis.read(readFileHash);

								if (Utility.hashIsEmpty(previousFileHash)) {
									log.error("Previous file hash not available");
									previousFileHash = Hex.encodeHexString(readFileHash);
								}

								newFileHash = Hex.encodeHexString(readFileHash);

								log.trace("New file hash = {}, old hash = {}", newFileHash, previousFileHash);

								if (!newFileHash.contentEquals(previousFileHash)) {

									if (applicationStatusRepository.findByStatusCode(ApplicationStatusCode.RECORD_HASH_MISMATCH_BYPASS_UNTIL_AFTER).compareTo(Utility.getFileName(fileName)) < 0) {
										// last file for which mismatch is allowed is in the past
										log.error("Hash mismatch for file {}. Previous = {}, Current = {}", fileName, previousFileHash, newFileHash);
										RecordFileLogger.rollback();
										return false;
									}
								}
								break;
							case FileDelimiter.RECORD_TYPE_RECORD:
								counter++;

								int byteLength = dis.readInt();
								byte[] rawBytes = new byte[byteLength];
								dis.readFully(rawBytes);
								Transaction transaction = Transaction.parseFrom(rawBytes);

								byteLength = dis.readInt();
								rawBytes = new byte[byteLength];
								dis.readFully(rawBytes);

								TransactionRecord txRecord = TransactionRecord.parseFrom(rawBytes);
								RecordFileLogger.storeRecord(transaction, txRecord);

								if (log.isTraceEnabled()) {
									log.trace("Transaction = {}, Record = {}", Utility.printTransaction(transaction), TextFormat.shortDebugString(txRecord));
								} else {
									log.debug("Stored transaction with consensus timestamp {}", txRecord.getConsensusTimestamp());
								}
								break;
							case FileDelimiter.RECORD_TYPE_SIGNATURE:
								int sigLength = dis.readInt();
								byte[] sigBytes = new byte[sigLength];
								dis.readFully(sigBytes);
								log.trace("File {} has signature {}", fileName, Hex.encodeHexString(sigBytes));
								break;

							default:
								log.error("Unknown record file delimiter {} for file {}", typeDelimiter, file);
								RecordFileLogger.rollback();
								return false;
						}
					} catch (Exception e) {
						log.error("Exception {}", e);
						RecordFileLogger.rollback();
						return false;
					}
				}

				log.trace("Calculated file hash for the current file {}", thisFileHash);

				RecordFileLogger.completeFile(thisFileHash, previousFileHash);
			} catch (Exception e) {
				log.error("Error parsing record file {} after {}", file, stopwatch, e);
				RecordFileLogger.rollback();
				return false;
			}

			log.info("Finished parsing {} transactions from record file {} in {}", counter, file.getName(), stopwatch);
			if (!Utility.hashIsEmpty(thisFileHash)) {
				applicationStatusRepository.updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, thisFileHash);
			}
			return true;
		} else if (initFileResult == INIT_RESULT.SKIP) {
			return true;
		} else {
			RecordFileLogger.rollback();
			return false;
		}
	}

	/**
	 * read and parse a list of record files
	 * @throws Exception 
	 */
	private void loadRecordFiles(List<String> fileNames) throws Exception {
		String prevFileHash = applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);
		Collections.sort(fileNames);

		for (String name : fileNames) {
			String thisFileHash = "";
			if (Utility.checkStopFile()) {
				log.info("Stop file found, stopping");
				return;
			}
			thisFileHash = Hex.encodeHexString(Utility.getFileHash(name));
			if (loadRecordFile(name, prevFileHash, thisFileHash)) {
				prevFileHash = thisFileHash;
				Utility.moveFileToParsedDir(name, "/parsedRecordFiles/");
			} else {
				return;
			}
		}
	}

	@Override
	@Scheduled(fixedRateString = "${hedera.mirror.record.parser.frequency:100}")
	public void parse() {
		try {
			if (!recordProperties.isEnabled()) {
				return;
			}

			if (Utility.checkStopFile()) {
				log.info("Stop file found");
				return;
			}

			String pathName = ConfigLoader.getDefaultParseDir(OPERATION_TYPE.RECORDS);
			log.debug("Parsing record files from {}", pathName);
			if (RecordFileLogger.start()) {

				File file = new File(pathName);
				if (file.isDirectory()) { //if it's a directory

					String[] files = file.list(); // get all files under the directory
					Arrays.sort(files);           // sorted by name (timestamp)

					// add directory prefix to get full path
					List<String> fullPaths = Arrays.asList(files).stream()
							.filter(f -> Utility.isRecordFile(f))
							.map(s -> file + "/" + s)
							.collect(Collectors.toList());

					if (fullPaths != null && fullPaths.size() != 0) {
						log.trace("Processing record files: {}", fullPaths);
						loadRecordFiles(fullPaths);
					} else {
						log.debug("No files to parse");
					}
				} else {
					log.error("Input parameter {} is not a folder", pathName);
				}
				RecordFileLogger.finish();
			}
		} catch (Exception e) {
			log.error("Error parsing files", e);
		}
	}

	/**
	 * Given a service record name, read its prevFileHash
	 *
	 * @param fileName
	 * 		the name of record file to read
	 * @return return previous file hash's Hex String
	 */
	public static String readPrevFileHash(String fileName) {
		File file = new File(fileName);
		if (file.exists() == false) {
			log.warn("File does not exist {}", fileName);
			return null;
		}
		byte[] prevFileHash = new byte[48];
		try (DataInputStream dis = new DataInputStream(new FileInputStream(file))) {
			// record_format_version
			dis.readInt();
			// version
			dis.readInt();

			byte typeDelimiter = dis.readByte();

			if (typeDelimiter == FileDelimiter.RECORD_TYPE_PREV_HASH) {
				dis.read(prevFileHash);
				String hexString = Hex.encodeHexString(prevFileHash);
				log.trace("Read previous file hash {} for file {}", hexString, fileName);
				return hexString;
			} else {
				log.error("Expecting previous file hash, but found file delimiter {} for file {}", typeDelimiter, fileName);
			}
		} catch (Exception e) {
			log.error("Error reading previous file hash {}", fileName, e);
		}

		return null;
	}
}
