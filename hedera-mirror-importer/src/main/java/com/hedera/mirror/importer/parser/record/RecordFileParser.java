package com.hedera.mirror.importer.parser.record;

/*-
 * ‌
 * Hedera Mirror Node
 * ​
 * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC
 * ​
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * ‍
 */

import io.micrometer.core.instrument.DistributionSummary;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Timer;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.InputStream;
import java.nio.file.Path;
import java.time.Duration;
import java.time.Instant;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;
import javax.inject.Named;
import lombok.extern.log4j.Log4j2;
import org.apache.commons.io.FileUtils;
import org.springframework.scheduling.annotation.Scheduled;

import com.hedera.mirror.importer.domain.ApplicationStatusCode;
import com.hedera.mirror.importer.domain.RecordFile;
import com.hedera.mirror.importer.domain.TransactionTypeEnum;
import com.hedera.mirror.importer.exception.DuplicateFileException;
import com.hedera.mirror.importer.exception.ParserException;
import com.hedera.mirror.importer.parser.FileParser;
import com.hedera.mirror.importer.parser.domain.RecordItem;
import com.hedera.mirror.importer.parser.domain.StreamFileData;
import com.hedera.mirror.importer.repository.ApplicationStatusRepository;
import com.hedera.mirror.importer.util.ShutdownHelper;
import com.hedera.mirror.importer.util.Utility;

/**
 * This is a utility file to read back service record file generated by Hedera node
 */
@Log4j2
@Named
@ConditionalOnRecordParser
public class RecordFileParser implements FileParser {

    private final ApplicationStatusRepository applicationStatusRepository;
    private final RecordParserProperties parserProperties;
    private final MeterRegistry meterRegistry;
    private final RecordItemListener recordItemListener;
    private final RecordStreamFileListener recordStreamFileListener;

    // Metrics
    private final Timer.Builder parseDurationMetric;
    private final Timer.Builder transactionLatencyMetric;
    private final DistributionSummary.Builder transactionSizeMetric;

    public RecordFileParser(ApplicationStatusRepository applicationStatusRepository,
                            RecordParserProperties parserProperties, MeterRegistry meterRegistry,
                            RecordItemListener recordItemListener,
                            RecordStreamFileListener recordStreamFileListener) {
        this.applicationStatusRepository = applicationStatusRepository;
        this.parserProperties = parserProperties;
        this.meterRegistry = meterRegistry;
        this.recordItemListener = recordItemListener;
        this.recordStreamFileListener = recordStreamFileListener;

        parseDurationMetric = Timer.builder("hedera.mirror.parse.duration")
                .description("The duration in seconds it took to parse the file and store it in the database")
                .tag("type", parserProperties.getStreamType().toString());

        transactionSizeMetric = DistributionSummary.builder("hedera.mirror.transaction.size")
                .description("The size of the transaction in bytes")
                .baseUnit("bytes");

        transactionLatencyMetric = Timer.builder("hedera.mirror.transaction.latency")
                .description("The difference in ms between the time consensus was achieved and the mirror node " +
                        "processed the transaction");
    }

    /**
     * Given a service record name, read and parse and return as a list of service record pair
     *
     * @param streamFileData containing information about file to be processed
     */
    public void loadRecordFile(StreamFileData streamFileData) {
        Instant startTime = Instant.now();
        recordStreamFileListener.onStart(streamFileData);
        RecordFile recordFile = Utility.parseRecordFile(streamFileData.getFilename(), true);
        String fileName = Utility.getFileName(streamFileData.getFilename());
        recordFile.setLoadStart(startTime.getEpochSecond());
        int counter = 0;
        boolean success = false;

        try {
            if (!Utility.verifyHashChain(recordFile.getPreviousHash(),
                    applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH),
                    parserProperties.getMirrorProperties().getVerifyHashAfter(), fileName)) {
                throw new ParserException("Hash mismatch for file " + fileName);
            }

            for (var recordItem : recordFile.getRecordItems()) {
                counter++;

                if (log.isTraceEnabled()) {
                    log.trace("Transaction = {}, Record = {}",
                            Utility.printProtoMessage(recordItem.getTransaction()),
                            Utility.printProtoMessage(recordItem.getRecord()));
                } else if (log.isDebugEnabled()) {
                    log.debug("Storing transaction with consensus timestamp {}", recordItem.getConsensusTimestamp());
                }
                recordItemListener.onItem(recordItem);

                String type = TransactionTypeEnum.of(recordItem.getTransactionType()).toString();
                transactionSizeMetric.tag("type", type)
                        .register(meterRegistry)
                        .record(recordItem.getTransactionBytes().length);

                Instant consensusTimestamp = Utility.convertToInstant(
                        recordItem.getRecord().getConsensusTimestamp());
                transactionLatencyMetric.tag("type", type)
                        .register(meterRegistry)
                        .record(Duration.between(consensusTimestamp, Instant.now()));
            }

            List<RecordItem> items = recordFile.getRecordItems();
            if (!items.isEmpty()) {
                recordFile.setConsensusStart(items.get(0).getConsensusTimestamp());
                recordFile.setConsensusEnd(items.get(items.size() - 1).getConsensusTimestamp());
            }
            recordFile.setLoadEnd(Instant.now().getEpochSecond());
            recordStreamFileListener.onEnd(recordFile);
            applicationStatusRepository.updateStatusValue(
                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());
            success = true;
        } finally {
            var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();
            var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter / elapsedTimeMillis) : 0;
            log.info("Finished parsing {} transactions from record file {} in {}ms ({}/s)",
                    counter, fileName, elapsedTimeMillis, rate);
            parseDurationMetric.tag("success", String.valueOf(success))
                    .tag("version", String.valueOf(recordFile.getRecordFormatVersion()))
                    .register(meterRegistry)
                    .record(elapsedTimeMillis, TimeUnit.MILLISECONDS);
        }
    }

    /**
     * read and parse a list of record files
     *
     * @throws Exception
     */
    private void loadRecordFiles(List<String> fileNames) {
        Collections.sort(fileNames);
        for (String name : fileNames) {
            if (ShutdownHelper.isStopping()) {
                return;
            }

            File file = new File(name);

            try (InputStream fileInputStream = new FileInputStream(file)) {
                loadRecordFile(new StreamFileData(name, fileInputStream));

                if (parserProperties.isKeepFiles()) {
                    Utility.archiveFile(file, parserProperties.getParsedPath());
                } else {
                    FileUtils.deleteQuietly(file);
                }
            } catch (FileNotFoundException e) {
                log.warn("File does not exist {}", name);
                return;
            } catch (Exception e) {
                log.error("Error parsing file {}", name, e);
                recordStreamFileListener.onError();
                if (!(e instanceof DuplicateFileException)) { // if DuplicateFileException, continue with other files
                    return;
                }
            }
        }
    }

    @Override
    @Scheduled(fixedRateString = "${hedera.mirror.importer.parser.record.frequency:500}")
    public void parse() {
        if (ShutdownHelper.isStopping()) {
            return;
        }
        Path path = parserProperties.getValidPath();
        log.debug("Parsing record files from {}", path);
        try {
            File file = path.toFile();
            if (file.isDirectory()) { //if it's a directory

                String[] files = file.list(); // get all files under the directory
                Arrays.sort(files);           // sorted by name (timestamp)

                // add directory prefix to get full path
                List<String> fullPaths = Arrays.asList(files).stream()
                        .map(s -> file + "/" + s)
                        .collect(Collectors.toList());

                if (fullPaths != null && fullPaths.size() != 0) {
                    log.trace("Processing record files: {}", fullPaths);
                    loadRecordFiles(fullPaths);
                } else {
                    log.debug("No files to parse");
                }
            } else {
                log.error("Input parameter is not a folder: {}", path);
            }
        } catch (Exception e) {
            log.error("Error parsing files", e);
        }
    }
}
