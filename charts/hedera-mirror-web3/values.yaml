affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          topologyKey: kubernetes.io/hostname
          labelSelector:
            matchLabels:
              app.kubernetes.io/component: web3

alertmanager:
  inhibitRules:
    enabled: false
    InhibitAllWhenPodIssues:
      enabled: true
      matches:
        - sourceMatch:
            - name: area
              value: resource
          targetMatch:
            - name: application
              value: hedera-mirror-web3
          equal:
            - namespace
            - pod

annotations: {}

config: {}

# Environment variables to add to the container. The value can either be a string or an EnvVarSource. Evaluated as a template.
env:
  SPRING_CLOUD_KUBERNETES_ENABLED: "true"
  SPRING_CONFIG_ADDITIONAL_LOCATION: "file:/usr/etc/hedera/"
  # FOO:
  #   valueFrom:
  #     secretKeyRef:
  #       name: "{{ .Release.Name }}-custom"
  #       key: BAR

# Add config maps or secrets as environment variables. Evaluated as a template.
envFrom: []
# - secretRef:
#     name: "{{ .Release.Name }}-env"

fullnameOverride: ""

global:
  image: {}
  middleware: false
  namespaceOverride: ""
  podAnnotations: {}

hpa:
  behavior: {}
  enabled: false
  maxReplicas: 8
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 80
  minReplicas: 1

image:
  pullPolicy: IfNotPresent
  registry: gcr.io
  repository: mirrornode/hedera-mirror-web3
  tag: ""  # Defaults to the chart's app version

imagePullSecrets: []

ingress:
  annotations:
    traefik.ingress.kubernetes.io/router.middlewares: '{{ include "hedera-mirror-web3.namespace" . }}-{{ include "hedera-mirror-web3.fullname" . }}@kubernetescrd'
  enabled: true
  hosts:
    - host: ""
      paths:
        # the rest of /api/v1/contracts will still be handled by the REST API logic, except for this one address
        - "/api/v1/contracts/call"
        - "/web3"
  tls:
    enabled: false
    secretName: ""

labels: {}

livenessProbe:
  httpGet:
    path: /actuator/health/liveness
    port: http
  initialDelaySeconds: 50
  periodSeconds: 10
  timeoutSeconds: 2

middleware:
  - retry:
      attempts: 3
      initialInterval: 100ms

nameOverride: ""

nodeSelector: {}

podAnnotations: {}

podDisruptionBudget:
  enabled: false
  # maxUnavailable: 0
  minAvailable: 50%

podSecurityContext:
  fsGroup: 1000
  runAsGroup: 1000
  runAsNonRoot: true
  runAsUser: 1000
  seccompProfile:
    type: RuntimeDefault

priorityClassName: ""

prometheusRules:
  enabled: false
  Web3Errors:
    annotations:
      description: "{{ $value | humanizePercentage }} Web3 server error rate for {{ $labels.namespace }}/{{ $labels.pod }}"
      summary: "Mirror Web3 API error rate exceeds 5%"
    enabled: true
    expr: sum(rate(http_server_requests_seconds_count{application="hedera-mirror-web3", status="SERVER_ERROR"}[5m])) by (namespace, pod) / sum(rate(http_server_requests_seconds_count{application="hedera-mirror-web3"}[5m])) by (namespace, pod) > 0.05
    for: 2m
    labels:
      application: hedera-mirror-web3
      severity: critical

  Web3HighCPU:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} CPU usage reached {{ $value | humanizePercentage }}"
      summary: "Mirror Web3 API CPU usage exceeds 80%"
    enabled: true
    expr: sum(process_cpu_usage{application="hedera-mirror-web3"}) by (namespace, pod) / sum(system_cpu_count{application="hedera-mirror-web3"}) by (namespace, pod) > 0.8
    for: 5m
    labels:
      application: hedera-mirror-web3
      area: resource
      severity: critical

  Web3HighDBConnections:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} is using {{ $value | humanizePercentage }} of available database connections"
      summary: "Mirror Web3 API database connection utilization exceeds 75%"
    enabled: true
    expr: sum(hikaricp_connections_active{application="hedera-mirror-web3"}) by (namespace, pod) / sum(hikaricp_connections_max{application="hedera-mirror-web3"}) by (namespace, pod) > 0.75
    for: 5m
    labels:
      application: hedera-mirror-web3
      area: resource
      severity: critical

  Web3HighFileDescriptors:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} file descriptor usage reached {{ $value | humanizePercentage }}"
      summary: "Mirror Web3 API file descriptor usage exceeds 80%"
    enabled: true
    expr: sum(process_files_open_files{application="hedera-mirror-web3"}) by (namespace, pod) / sum(process_files_max_files{application="hedera-mirror-web3"}) by (namespace, pod) > 0.8
    for: 5m
    labels:
      application: hedera-mirror-web3
      area: resource
      severity: critical

  Web3HighMemory:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} memory usage reached {{ $value | humanizePercentage }}"
      summary: "Mirror Web3 API memory usage exceeds 80%"
    enabled: true
    expr: sum(jvm_memory_used_bytes{application="hedera-mirror-web3"}) by (namespace, pod) / sum(jvm_memory_max_bytes{application="hedera-mirror-web3"}) by (namespace, pod) > 0.8
    for: 5m
    labels:
      application: hedera-mirror-web3
      area: resource
      severity: critical

  Web3LogErrors:
    annotations:
      description: "Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 3m period"
      summary: "High rate of log errors"
    enabled: true
    expr: sum(increase(log4j2_events_total{application="hedera-mirror-web3", level="error"}[1m])) by (namespace, pod) >= 2
    for: 3m
    labels:
      application: hedera-mirror-web3
      severity: critical

  Web3NoPodsReady:
    annotations:
      description: "No Web3 API instances are currently running in {{ $labels.namespace }}"
      summary: No Web3 API instances running
    enabled: true
    expr: sum(kube_pod_status_ready{pod=~".*-web3-.*",condition="true"}) by (namespace) < 1
    for: 2m
    labels:
      application: hedera-mirror-web3
      area: resource
      severity: critical

  Web3NoRequests:
    annotations:
      description: "Web3 API has not seen any requests to {{ $labels.namespace }} for 5m"
      summary: "No Web3 API requests seen for awhile"
    enabled: true
    expr: sum(rate(http_server_requests_seconds_count{application="hedera-mirror-web3"}[3m])) by (namespace) <= 0
    for: 5m
    labels:
      application: hedera-mirror-web3
      severity: warning

  Web3QueryLatency:
    annotations:
      description: "High average database query latency of {{ $value | humanizeDuration }} for {{ $labels.namespace }}/{{ $labels.pod }}"
      summary: "Mirror Web3 API query latency exceeds 1s"
    enabled: true
    expr: sum(rate(spring_data_repository_invocations_seconds_sum{application="hedera-mirror-web3"}[5m])) by (namespace, pod) / sum(rate(spring_data_repository_invocations_seconds_count{application="hedera-mirror-web3"}[5m])) by (namespace, pod) > 1
    for: 1m
    labels:
      application: hedera-mirror-web3
      severity: warning

  Web3RequestLatency:
    annotations:
      description: "High average request latency of {{ $value | humanizeDuration }} for {{ $labels.namespace }}/{{ $labels.pod }}"
      summary: "Mirror Web3 API request latency exceeds 2s"
    enabled: true
    expr: sum(rate(http_server_requests_seconds_sum{application="hedera-mirror-web3"}[5m])) by (namespace, pod) / sum(rate(http_server_requests_seconds_count{application="hedera-mirror-web3"}[5m])) by (namespace, pod) > 2
    for: 1m
    labels:
      application: hedera-mirror-web3
      severity: warning

rbac:
  enabled: true

readinessProbe:
  httpGet:
    path: /actuator/health/readiness
    port: http
  initialDelaySeconds: 40
  timeoutSeconds: 2

# Only set if HPA is disabled
# replicas: 1

resources:
  limits:
    cpu: 2
    memory: 2048Mi
  requests:
    cpu: 100m
    memory: 128Mi

revisionHistoryLimit: 3

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop: [ALL]
  readOnlyRootFilesystem: true

service:
  annotations: {}
  port: 80
  type: ClusterIP

serviceAccount:
  create: true
  # The name of the service account to use. If not set and create is true, a name is generated using the fullname template
  name:

serviceMonitor:
  enabled: false
  interval: 30s

terminationGracePeriodSeconds: 60

test:
  annotations:
    helm.sh/hook: test-success
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  enabled: true
  image:
    pullPolicy: IfNotPresent
    repository: postman/newman
    tag: 5.3.1-alpine
  postman: ""  # Custom postman.json in base64 encoding

tolerations: []

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 10%
    maxUnavailable: 25%

# Volumes to add to the container. The key is the volume name and the value is the volume mount definition. The same keys should also appear in volumes below.
volumeMounts:
  config:
    mountPath: /usr/etc/hedera

# Volume mounts to add to the container. The key is the volume name and the value is the volume definition. Evaluated as a template.
volumes:
  config:
    secret:
      defaultMode: 420
      secretName: '{{ include "hedera-mirror-web3.fullname" . }}'
