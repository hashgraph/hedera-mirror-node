affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          topologyKey: kubernetes.io/hostname
          labelSelector:
            matchLabels:
              app.kubernetes.io/component: grpc

annotations: {}

config:
  hedera:
    mirror:
      grpc:
        db: {}

fullnameOverride: ""

global:
  namespaceOverride: ""
  redis:
    password: redis_password

hpa:
  enabled: false
  maxReplicas: 3
  minReplicas: 1
  utilization: 80

image:
  pullPolicy: IfNotPresent
  repository: gcr.io/mirrornode/hedera-mirror-grpc
  tag: ""  # Default to the chart's app version

imagePullSecrets: []

ingress:
  annotations:
    traefik.ingress.kubernetes.io/router.middlewares: '{{ include "hedera-mirror-grpc.namespace" . }}-{{ include "hedera-mirror-grpc.fullname" . }}@kubernetescrd'
  enabled: true
  hosts:
    - host: ""
      paths:
        - "/com.hedera.mirror.api.proto.ConsensusService"
        - "/grpc.reflection.v1alpha.ServerReflection"
  middleware:
    circuitBreaker: NetworkErrorRatio() > 0.10 || ResponseCodeRatio(500, 600, 0, 600) > 0.25
    connectionsPerIP: 5
    enabled: false
    ipWhitelist:
      - 0.0.0.0/0
    rateLimit:
      average: 100
      burst: 250
  tls:
    enabled: false
    secretName: ""

labels: {}

livenessProbe:
  httpGet:
    path: /actuator/health/liveness
    port: http
  initialDelaySeconds: 50
  periodSeconds: 10
  timeoutSeconds: 2

nodeSelector: {}

podSecurityContext:
  fsGroup: 1000

priorityClassName: ""

prometheusRules:
  enabled: true
  GrpcNoSubscribers:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} has {{ $value }} subscribers for {{ $labels.type }}"
      summary: "Mirror gRPC API has no subscribers"
    enabled: true
    expr: sum(hedera_mirror_subscribers{application="hedera-mirror-grpc"}) by (namespace, pod, type) <= 0
    for: 5m
    labels:
      severity: warning

  GrpcErrors:
    annotations:
      description: '{{ $value | humanizePercentage }}% gRPC {{ $labels.statusCode }} error rate for {{ $labels.namespace }}/{{ $labels.pod }}'
      summary: "Mirror gRPC API error rate exceeds 5%"
    enabled: true
    expr: sum(rate(grpc_server_processing_duration_seconds_count{application="hedera-mirror-grpc", statusCode!~"DEADLINE_EXCEEDED|INVALID_ARGUMENT|NOT_FOUND|OK|RESOURCE_EXHAUSTED"}[5m])) by (namespace, pod, statusCode) / sum(rate(grpc_server_processing_duration_seconds_count{application="hedera-mirror-grpc"}[5m])) by (namespace, pod, statusCode) > 0.05
    for: 2m
    labels:
      severity: critical

  GrpcHighLatency:
    annotations:
      description: 'High latency of {{ $value }}s between the main nodes and {{ $labels.namespace }}/{{ $labels.pod }}'
      summary: "Mirror gRPC API consensus to delivery (C2MD) latency exceeds 15s"
    enabled: true
    expr: sum(rate(hedera_mirror_publish_latency_seconds_sum{application="hedera-mirror-grpc"}[5m])) by (namespace, pod) / sum(rate(hedera_mirror_publish_latency_seconds_count{application="hedera-mirror-grpc"}[5m])) by (namespace, pod) > 15
    for: 1m
    labels:
      severity: critical

  GrpcHighCPU:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} CPU usage reached {{ $value | humanizePercentage }}%"
      summary: "Mirror gRPC API CPU usage exceeds 80%"
    enabled: true
    expr: sum(process_cpu_usage{application="hedera-mirror-grpc"}) by (namespace, pod) / sum(system_cpu_count{application="hedera-mirror-grpc"}) by (namespace, pod) > 0.8
    for: 5m
    labels:
      severity: critical

  GrpcHighDBConnections:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} is using {{ $value | humanizePercentage }}% of available database connections"
      summary: "Mirror gRPC API database connection utilization exceeds 75%"
    enabled: true
    expr: sum(hikaricp_connections_active{application="hedera-mirror-grpc"}) by (namespace, pod) / sum(hikaricp_connections_max{application="hedera-mirror-grpc"}) by (namespace, pod) > 0.75
    for: 5m
    labels:
      severity: critical

  GrpcHighFileDescriptors:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} file descriptor usage reached {{ $value | humanizePercentage }}%"
      summary: "Mirror gRPC API file descriptor usage exceeds 80%"
    enabled: true
    expr:  sum(process_files_open_files{application="hedera-mirror-grpc"}) by (namespace, pod) / sum(process_files_max_files{application="hedera-mirror-grpc"}) by (namespace, pod) > 0.8
    for: 5m
    labels:
      severity: critical

  GrpcHighMemory:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} memory usage reached {{ $value | humanizePercentage }}%"
      summary: "Mirror gRPC API memory usage exceeds 80%"
    enabled: true
    expr: sum(jvm_memory_used_bytes{application="hedera-mirror-grpc"}) by (namespace, pod) / sum(jvm_memory_max_bytes{application="hedera-mirror-grpc"}) by (namespace, pod) > 0.8
    for: 5m
    labels:
      severity: critical

  GrpcLog4j2Errors:
    annotations:
      description: "{{ $labels.namespace }}/{{ $labels.pod }} encountered {{ $value }} exceptions in a 2m period"
      summary: "High rate of log4j2 errors"
    enabled: true
    expr: sum(increase(log4j2_events_total{application="hedera-mirror-grpc", level="error"}[2m])) by (namespace, pod) >= 2
    for: 3m
    labels:
      severity: critical

rbac:
  enabled: true

readinessProbe:
  httpGet:
    path: /actuator/health/readiness
    port: http
  initialDelaySeconds: 40
  timeoutSeconds: 2

# Only set if HPA is disabled
# replicas: 1

resources:
  limits:
    cpu: 500m
    memory: 750Mi
  requests:
    cpu: 100m
    memory: 128Mi

revisionHistoryLimit: 3

securityContext:
  capabilities:
    drop: [ALL]
  readOnlyRootFilesystem: true
  runAsGroup: 1000
  runAsNonRoot: true
  runAsUser: 1000

service:
  annotations:
    traefik.ingress.kubernetes.io/service.serversscheme: h2c
  port: 5600
  type: ClusterIP

serviceAccount:
  create: true
  # The name of the service account to use. If not set and create is true, a name is generated using the fullname template
  name:

serviceMonitor:
  enabled: false
  interval: 30s

terminationGracePeriodSeconds: 60

tolerations: []

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 10%
    maxUnavailable: 25%
