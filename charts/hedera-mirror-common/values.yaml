global:
  namespaceOverride: ""

labels: {}

loki:
  enabled: true
  gateway:
    enabled: false
  loki:
    auth_enabled: false
    commonConfig:
      replication_factor: 1
    storage:
      type: 'filesystem'
    structuredConfig:
      ruler:
        alertmanager_url: http://{{ .Release.Name }}-prometheus-alertmanager:9093
        enable_alertmanager_v2: true
        enable_api: true
        ring:
          kvstore:
            store: inmemory
        rule_path: /tmp/scratch
        storage:
          type: local
          local:
            directory: /rules
      table_manager:
        retention_deletes_enabled: true
        retention_period: 2184h
  monitoring:
    lokiCanary:
      enabled: false
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false
  persistence:
    enableStatefulSetAutoDeletePVC: true
    size: 100Gi
  rules:
    - name: hedera-mirror-grpc
      rules:
        - alert: GrpcLogErrors
          annotations:
            description: "Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 3m period"
            summary: High rate of errors in logs
          expr: >
            sum(rate({component="grpc"}
              | regexp `(?P<timestamp>\S+) (?P<level>\S+) (?P<thread>\S+) (?P<class>\S+) (?P<message>.+)`
              | level = "ERROR"
              != "reactor.core.publisher"
              != "drainError"
              != "org.springframework"
              != "connection validation failed"
              != "Stream closed before write could take place"
              != "Connection unexpectedly closed"
              != "Unknown error subscribing to topic"
              != "Error has been observed at the following"
              != "ReactorNettyClient$PostgresConnectionClosedException: Connection closed"
              != "i.g.n.s.i.g.n.NettyServerHandler Stream Error"
              != "Http2Exception.streamError"
              != "readAddress(..) failed: Connection reset by peer"
              != "i.r.p.c.ReactorNettyClient Connection Error"
              != "i.n.u.ResourceLeakDetector LEAK: ByteBuf.release()"
              != "Not a valid topic"
              != "Must be greater than or equal to 0"
              != "Topic does not exist"
            [1m])) by (namespace, pod) > 1
          for: 3m
          labels:
            severity: critical
    - name: hedera-mirror-importer
      rules:
        - alert: ImporterLogErrors
          annotations:
            description: "Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 5m period"
            summary: High rate of errors in logs
          expr: >
            sum(rate({component="importer"}
              | regexp `(?P<timestamp>\S+) (?P<level>\S+) (?P<thread>\S+) (?P<class>\S+) (?P<message>.+)`
              | level = "ERROR"
              != "UnusedChannelExceptionHandler"
              | message =~ ".*(Exception|hash mismatch for file|Unknown record file delimiter|Unknown file delimiter|Error parsing record file|Expecting previous file hash|Unable to extract hash and signature from file|Failed to verify record files|Account balance dataset timestamp mismatch!|ERRORS processing account balances file|does not exist in the database|Unable to connect to database|Address book file).*"
            [1m])) by (namespace, pod) > 0.5
          for: 5m
          labels:
            severity: critical
        - alert: ImporterRecoverableErrors
          annotations:
            description: "Recoverable Error Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 1m period"
            summary: Recoverable Error found in logs
          expr: >
            sum(count_over_time({component="importer"}
              | regexp `(?P<timestamp>\S+) (?P<level>\S+) (?P<thread>\S+) (?P<class>\S+) (?P<message>.+)`
              | level = "ERROR"
              | message =~ ".*Recoverable error.*"
            [1m])) by (namespace, pod) > 0
          labels:
            severity: critical
    - name: hedera-mirror-rest
      rules:
        - alert: RestLogErrors
          annotations:
            description: "Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 1m period"
            summary: "High rate of log errors"
          expr: >
            sum(rate({component="rest"}
              | regexp `(?P<timestamp>\S+) (?P<level>\S+) (?P<requestId>\S+) (?P<message>.+)`
              | level = "ERROR" or level = "FATAL"
            [1m])) by (namespace, pod) > 0.04
          for: 1m
          labels:
            severity: critical
    - name: hedera-mirror-rosetta
      rules:
        - alert: RosettaLogErrors
          annotations:
            description: "Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 1m period"
            summary: "High rate of log errors"
          expr: >
            sum(rate({component="rosetta"}
              | logfmt
              | level = "error" or level = "fatal"
            [1m])) by (namespace, pod) > 0.04
          for: 1m
          labels:
            severity: critical
  serviceMonitor:
    enabled: true
  singleBinary:
    extraVolumeMounts:
      - mountPath: /rules
        name: rules
    extraVolumes:
      - name: rules
        configMap:
          defaultMode: 420
          name: mirror-log-alerts
    replicas: 1
    resources:
      limits:
        cpu: 200m
        memory: 384Mi
      requests:
        cpu: 50m
        memory: 64Mi
  test:
    enabled: false

networkPolicy:
  enabled: false

priorityClass:
  enabled: true

prometheus-adapter:
  enabled: true
  priorityClassName: low
  prometheus:
    url: http://{{ .Release.Name }}-prometheus-prometheus
  resources:
    limits:
      cpu: 50m
      memory: 100Mi
    requests:
      cpu: 25m
      memory: 50Mi
  rules:
    default: false
    custom:  # This is a custom rule which exposes (requests_per_second) from the prometheus adapter to be used by any Horizontal Pod Autoscaler.
      - seriesQuery: 'api_all_request_total{namespace!="",pod!=""}'
        resources:
          overrides:
            namespace:
              resource: "namespace"
            pod:
              resource: "pod"
        name:
          as: "requests_per_second"
        metricsQuery: "sum(rate(<<.Series>>{<<.LabelMatchers>>}[3m])) by (<<.GroupBy>>)"

prometheus:
  alertmanager:
    alertmanagerSpec:
      alertmanagerConfigSelector:
        matchLabels:
          app.kubernetes.io/part-of: hedera-mirror-node
      priorityClassName: low
      resources:
        limits:
          cpu: 50m
          memory: 80Mi
        requests:
          cpu: 30m
          memory: 30Mi
    config:
      receivers:
        - name: 'null'
      route:
        group_by:
          - namespace
          - alertname
        group_wait: 30s
        receiver: 'null'
        repeat_interval: 7d
        routes: []
      templates:
        - '/etc/alertmanager/config/slack.tmpl'
    enabled: true
    templateFiles:
      slack.tmpl: |-
        {{- define "slack.title" -}}
        {{- .Status | title }} {{ .CommonLabels.alertname }}{{ if .CommonLabels.namespace }} in {{ .CommonLabels.namespace }}{{ end }}
        {{- end -}}

        {{- define "slack.text" -}}
        {{ range .Alerts -}}
        *Summary:* {{ if .Annotations.summary }}{{ .Annotations.summary }}{{ else }}{{ .Annotations.message }}{{ end }}{{"\n"}}
        {{- if .Annotations.description }} *Description:* {{ .Annotations.description }}{{"\n"}}{{ end }}
        *Prometheus:* *<{{ .GeneratorURL }}|:fire:>* {{- if .Annotations.dashboard_url }}     *Grafana:* *<{{ .Annotations.dashboard_url }}|:chart_with_upwards_trend:>*{{ end }}{{- if .Annotations.runbook_url }}      *Runbook:* *<{{ .Annotations.runbook_url }}|:notebook:>*{{ end }}

        *Labels:*
          {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
          {{ end }}
        {{ end }}
        {{- end -}}
  coreDns:
    enabled: false
  enabled: true
  grafana:
    additionalDataSources:
      - name: AlertManager
        type: camptocamp-prometheus-alertmanager-datasource
        access: proxy
        url: http://{{ .Release.Name }}-prometheus-alertmanager:9093
      - name: Loki
        type: loki
        access: proxy
        url: http://{{ .Release.Name }}-loki:3100
        jsonData:
          maxLines: 500
    adminPassword: ""  # Randomly generated if left blank
    defaultDashboardsEnabled: true
    plugins:
      - camptocamp-prometheus-alertmanager-datasource
    resources:
      limits:
        cpu: 300m
        memory: 500Mi
      requests:
        cpu: 150m
        memory: 75Mi
  kube-state-metrics:
    resources:
      limits:
        cpu: 10m
        memory: 64Mi
      requests:
        cpu: 5m
        memory: 16Mi
  # We disable these exporters because they either don't work in GKE or produce too many time series
  kubeApiServer:
    enabled: false
  kubeControllerManager:
    enabled: false
  kubeDns:
    enabled: false
  kubeEtcd:
    enabled: false
  kubelet:
    # Disable these high cardinality metrics
    serviceMonitor:
      cAdvisorMetricRelabelings:
        - action: drop
          regex: container_(memory_failures_total|tasks_state)
          sourceLabels: [__name__]
      metricRelabelings:
        - action: drop
          regex: .*_bucket
          sourceLabels: [__name__]
  kubeProxy:
    enabled: false
  kubeScheduler:
    enabled: false
  prometheus-node-exporter:
    hostNetwork: false
    resources:
      limits:
        cpu: 100m
        memory: 50Mi
      requests:
        cpu: 50m
        memory: 20Mi
  prometheus:
    additionalPodMonitors:
      - name: traefik
        podMetricsEndpoints:
          - port: metrics
            path: /metrics
            interval: 15s
        selector:
          matchLabels:
            app.kubernetes.io/name: traefik
    prometheusSpec:
      podMonitorSelectorNilUsesHelmValues: false
      priorityClassName: low
      resources:
        limits:
          cpu: 750m
          memory: 2Gi
        requests:
          cpu: 250m
          memory: 250Mi
      retention: 60d
      ruleSelectorNilUsesHelmValues: false
      scrapeInterval: 30s
      serviceMonitorSelectorNilUsesHelmValues: false
      storageSpec:
        volumeClaimTemplate:
          spec:
            resources:
              requests:
                storage: 100Gi
      walCompression: true
  prometheusOperator:
    resources:
      limits:
        cpu: 100m
        memory: 200Mi
      requests:
        cpu: 50m
        memory: 50Mi

promtail:
  config:
    clients:
      - url: http://{{ .Release.Name }}-loki:3100/loki/api/v1/push
    snippets:
      pipelineStages:
        - cri: {}
        - multiline:
            firstline: '^\d{4}-\d{2}-\d{2}T\d{1,2}:\d{2}:\d{2}\.\d+(Z|[+-]\d{4}) '
  enabled: true
  resources:
    limits:
      cpu: 125m
      memory: 150Mi
    requests:
      cpu: 50m
      memory: 50Mi
  serviceMonitor:
    enabled: true

stackgres:
  enabled: false

testkube:
  enabled: false
  namespace: testkube
  test:
    duration: 300s
    extraExecutionRequestVariables: {}
    gitBranch: ""  # Default to .Chart.AppVersion
    schedule: ""  # Cron schedule of the test suite, default to no schedule
    target:
      namespace: ""
      release: mirror
    vus: 500
  trigger:
    enabled: false

traefik:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: traefik
  deployment:
    kind: DaemonSet
  enabled: true
  globalArguments:  # Expose X-Forwarded-For header for tracing
    - --entryPoints.web.forwardedHeaders.insecure
    - --entryPoints.websecure.forwardedHeaders.insecure
  logs:
    access:
      enabled: true
      filters:
        statuscodes: 400-599
  metrics:
    prometheus:
      addServicesLabels: true
  podDisruptionBudget:
    enabled: true
    minAvailable: 1
  ports:
    websecure:
      tls:
        enabled: true
  priorityClassName: critical
  resources:
    limits:
      cpu: 1500m
      memory: 2000Mi
    requests:
      cpu: 1000m
      memory: 500Mi
  service:
    spec: {}
    type: ClusterIP

zfs:
  analytics:
    enabled: false
  coordinator:
    diskSize: 300GB
  enabled: false
  init:
    diskPrefix: citus
    image:
      pullPolicy: IfNotPresent
      registry: gcr.io
      repository: google.com/cloudsdktool/google-cloud-cli
      tag: slim
    serviceAccount:
      name: zfs-service-account
      iAmName: sa-name@project.iam.gserviceaccount.com
  parameters:
    compression: zstd-6
    fstype: zfs
    poolname: zfspv-pool
    recordsize: 32k
  worker:
    diskSize: 3200GB
  zfsNode:
    nodeSelector:
      csi-type: zfs
    tolerations:
      - effect: NoSchedule
        key: zfs
        operator: Equal
        value: "true"
    additionalVolumes:
      node:
        hostPath:
          path: /
      scripts:
        configMap:
          name: "{{ .Release.Name }}-zfs-init"
          defaultMode: 0744
    initContainers:
      label-wait:
        image: gcr.io/google.com/cloudsdktool/google-cloud-cli:slim
        imagePullPolicy: IfNotPresent
        command: ["/scripts/label-wait.sh"]
        env:
          - name: ROOT_MOUNT_DIR
            value: /node
        securityContext:
          privileged: true
        volumeMounts:
          - name: node
            mountPath: /node
          - name: scripts
            mountPath: /scripts
  zfsPlugin:
    image:
      registry: gcr.io/
      repository: mirrornode/zfs-driver
      pullPolicy: IfNotPresent
      tag: 2.3.1-HEDERA
